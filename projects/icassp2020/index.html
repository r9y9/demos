<!DOCTYPE html>
<html lang="en-us">
<head>
<meta charset="utf-8">
<meta name="generator" content="Hugo 0.75.1" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<link rel="stylesheet" href="https://r9y9.github.io/demos/css/normalize.css">
<link rel="stylesheet" href="https://r9y9.github.io/demos/css/skeleton.css">
<link rel="stylesheet" href="https://r9y9.github.io/demos/css/custom.css">
<link rel="alternate" href="index.xml" type="application/rss+xml" title="List of demos">
<link rel="shortcut icon" href="favicon.png" type="image/x-icon" />
<title>Parallel WaveGAN: A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram - List of demos</title>
</head>
<body>

<div class="container">

	<header role="banner">
		
	</header>


	<main role="main">
		<article itemscope itemtype="http://schema.org/BlogPosting">
			<h1 class="entry-title" itemprop="headline">Parallel WaveGAN: A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram</h1>
			<span class="entry-meta"><time itemprop="datePublished" datetime="2019-10-21">October 21, 2019</time></span>
			<section itemprop="entry-text">
				

<p>Preprint: <a href="https://arxiv.org/abs/1910.11480">arXiv:1910.11480</a> (accepted to <a href="https://2020.ieeeicassp.org/">ICASSP 2020</a>)</p>

<ul>
<li><a href="#audio-samples-japanese">Audio samples (Japanese)</a></li>
<li><a href="#audio-samples-english">Audio samples (English)</a></li>
</ul>

<p><em>Japanese samples were used in the subjective evaluations reported in our paper.</em></p>

<h2 id="authors">Authors</h2>

<ul>
<li>Ryuichi Yamamoto (LINE Corp.)</li>
<li>Eunwoo Song (NAVER Corp.)</li>
<li>Jae-Min Kim (NAVER Corp.)</li>
</ul>

<h2 id="abstract">Abstract</h2>

<p>We propose Parallel WaveGAN<sup class="footnote-ref" id="fnref:1"><a href="#fn:1">1</a></sup>, a distillation-free, fast, and small-footprint waveform generation method using a generative adversarial network. In the proposed method, a non-autoregressive WaveNet is trained by jointly optimizing multi-resolution spectrogram and adversarial loss functions, which can effectively capture the time-frequency distribution of the realistic speech waveform. As our method does not require density distillation used in the conventional teacher-student framework, the entire model can be easily trained even with a small number of parameters. In particular, the proposed Parallel WaveGAN has only 1.44 M parameters and can generate 24 kHz speech waveform 28.68 times faster than real-time on a single GPU environment. Perceptual listening test results verify that our proposed method achieves 4.16 mean opinion score within a Transformer-based text-to-speech framework, which is comparative to the best distillation-based Parallel WaveNet system.</p>

<div align="center"><img src="https://r9y9.github.io/demos/images/icassp2020_fig.png" width="60%" /></div>

<h3 id="systems-used-for-comparision">Systems used for comparision</h3>

<ul>
<li><strong>Ground truth</strong>: Recorded speech.</li>
<li><strong>WaveNet</strong>: Gaussian WaveNet <a href="https://arxiv.org/abs/1807.07281">[1]</a></li>
<li><strong>ClariNet-$L^{(1)}$</strong>: ClariNet <a href="https://arxiv.org/abs/1807.07281">[1]</a> with the single STFT auxiliary loss</li>
<li><strong>ClariNet-$L^{(1,2,3)}$</strong>: ClariNet with the multi-resolution STFT loss</li>
<li><strong>ClariNet-GAN-$L^{(1,2,3)}$</strong>: ClariNet with the multi-resolution STFT and adversarial losses <a href="https://arxiv.org/abs/1807.07281">[2]</a></li>
<li><strong>Parallel WaveGAN-$L^{(1)}$</strong>: Parallel WaveGAN with th single STFT loss</li>
<li><strong>Parallel WaveGAN-$L^{(1,2,3)}$</strong>: Parallel WaveGAN with the multi-resolution STFT loss</li>
</ul>

<h2 id="audio-samples-japanese">Audio samples (Japanese)</h2>

<ol>
<li>Analysis/synthesis</li>
<li>Text-to-speech (Transformer TTS + vocoder models)</li>
</ol>

<h3 id="analysis-synthesis">Analysis/synthesis</h3>

<p><p>Sample 1</p>
<table><thead>
<tr><th>Ground truth</th><th>WaveNet</th><th>ClariNet-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample01]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample01]-2-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample01]-3-ClariNet (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>ClariNet-$L^{(1,2,3)}$</th><th>ClariNet-GAN-$L^{(1,2,3)}$</th><th>Parallel WaveGAN-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample01]-4-ClariNet (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample01]-5-ClariNet-GAN (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample01]-6-Parallel WaveGAN (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>Parallel WaveGAN-$L^{(1,2,3)}$ <font color="#0000cd">(ours)</font></th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample01]-7-Parallel WaveGAN (3spec) (ours).wav" type="audio/wav"></audio></td>
</tr></tbody></table><p>Sample 2</p>
<table><thead>
<tr><th>Ground truth</th><th>WaveNet</th><th>ClariNet-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample02]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample02]-2-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample02]-3-ClariNet (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>ClariNet-$L^{(1,2,3)}$</th><th>ClariNet-GAN-$L^{(1,2,3)}$</th><th>Parallel WaveGAN-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample02]-4-ClariNet (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample02]-5-ClariNet-GAN (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample02]-6-Parallel WaveGAN (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>Parallel WaveGAN-$L^{(1,2,3)}$ <font color="#0000cd">(ours)</font></th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample02]-7-Parallel WaveGAN (3spec) (ours).wav" type="audio/wav"></audio></td>
</tr></tbody></table><p>Sample 3</p>
<table><thead>
<tr><th>Ground truth</th><th>WaveNet</th><th>ClariNet-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample03]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample03]-2-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample03]-3-ClariNet (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>ClariNet-$L^{(1,2,3)}$</th><th>ClariNet-GAN-$L^{(1,2,3)}$</th><th>Parallel WaveGAN-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample03]-4-ClariNet (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample03]-5-ClariNet-GAN (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample03]-6-Parallel WaveGAN (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>Parallel WaveGAN-$L^{(1,2,3)}$ <font color="#0000cd">(ours)</font></th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample03]-7-Parallel WaveGAN (3spec) (ours).wav" type="audio/wav"></audio></td>
</tr></tbody></table><p>Sample 4</p>
<table><thead>
<tr><th>Ground truth</th><th>WaveNet</th><th>ClariNet-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample04]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample04]-2-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample04]-3-ClariNet (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>ClariNet-$L^{(1,2,3)}$</th><th>ClariNet-GAN-$L^{(1,2,3)}$</th><th>Parallel WaveGAN-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample04]-4-ClariNet (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample04]-5-ClariNet-GAN (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample04]-6-Parallel WaveGAN (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>Parallel WaveGAN-$L^{(1,2,3)}$ <font color="#0000cd">(ours)</font></th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample04]-7-Parallel WaveGAN (3spec) (ours).wav" type="audio/wav"></audio></td>
</tr></tbody></table><p>Sample 5</p>
<table><thead>
<tr><th>Ground truth</th><th>WaveNet</th><th>ClariNet-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample05]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample05]-2-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample05]-3-ClariNet (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>ClariNet-$L^{(1,2,3)}$</th><th>ClariNet-GAN-$L^{(1,2,3)}$</th><th>Parallel WaveGAN-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample05]-4-ClariNet (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample05]-5-ClariNet-GAN (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample05]-6-Parallel WaveGAN (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>Parallel WaveGAN-$L^{(1,2,3)}$ <font color="#0000cd">(ours)</font></th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample05]-7-Parallel WaveGAN (3spec) (ours).wav" type="audio/wav"></audio></td>
</tr></tbody></table></p>

<h3 id="text-to-speech">Text-to-speech</h3>

<p><p>Sample 1</p>
<table><thead>
<tr><th>Ground truth</th><th>Transformer + WaveNet</th><th>Transformer + ClariNet-$L^{(1,2,3)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample01]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample01]-2-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample01]-4-ClariNet (3spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>Transformer + ClariNet-GAN-$L^{(1,2,3)}$</th><th>Transformer + Parallel WaveGAN&ndash;$L^{(1,2,3)}$ <font color="#0000cd">(ours)</font></th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample01]-5-ClariNet-GAN (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample01]-7-Parallel WaveGAN (3spec) (ours).wav" type="audio/wav"></audio></td>
</tr></tbody></table><p>Sample 2</p>
<table><thead>
<tr><th>Ground truth</th><th>Transformer + WaveNet</th><th>Transformer + ClariNet-$L^{(1,2,3)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample02]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample02]-2-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample02]-4-ClariNet (3spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>Transformer + ClariNet-GAN-$L^{(1,2,3)}$</th><th>Transformer + Parallel WaveGAN&ndash;$L^{(1,2,3)}$ <font color="#0000cd">(ours)</font></th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample02]-5-ClariNet-GAN (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample02]-7-Parallel WaveGAN (3spec) (ours).wav" type="audio/wav"></audio></td>
</tr></tbody></table><p>Sample 3</p>
<table><thead>
<tr><th>Ground truth</th><th>Transformer + WaveNet</th><th>Transformer + ClariNet-$L^{(1,2,3)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample03]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample03]-2-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample03]-4-ClariNet (3spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>Transformer + ClariNet-GAN-$L^{(1,2,3)}$</th><th>Transformer + Parallel WaveGAN&ndash;$L^{(1,2,3)}$ <font color="#0000cd">(ours)</font></th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample03]-5-ClariNet-GAN (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample03]-7-Parallel WaveGAN (3spec) (ours).wav" type="audio/wav"></audio></td>
</tr></tbody></table><p>Sample 4</p>
<table><thead>
<tr><th>Ground truth</th><th>Transformer + WaveNet</th><th>Transformer + ClariNet-$L^{(1,2,3)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample04]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample04]-2-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample04]-4-ClariNet (3spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>Transformer + ClariNet-GAN-$L^{(1,2,3)}$</th><th>Transformer + Parallel WaveGAN&ndash;$L^{(1,2,3)}$ <font color="#0000cd">(ours)</font></th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample04]-5-ClariNet-GAN (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample04]-7-Parallel WaveGAN (3spec) (ours).wav" type="audio/wav"></audio></td>
</tr></tbody></table><p>Sample 5</p>
<table><thead>
<tr><th>Ground truth</th><th>Transformer + WaveNet</th><th>Transformer + ClariNet-$L^{(1,2,3)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/AnaSyn/[Sample05]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample05]-2-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample05]-4-ClariNet (3spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>Transformer + ClariNet-GAN-$L^{(1,2,3)}$</th><th>Transformer + Parallel WaveGAN&ndash;$L^{(1,2,3)}$ <font color="#0000cd">(ours)</font></th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample05]-5-ClariNet-GAN (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/TTS/[Sample05]-7-Parallel WaveGAN (3spec) (ours).wav" type="audio/wav"></audio></td>
</tr></tbody></table></p>

<h2 id="audio-samples-english">Audio samples (English)</h2>

<ol>
<li>Analysis/synthesis</li>
<li>Text-to-speech (<a href="https://arxiv.org/abs/1910.10909">ESPnet-TTS</a> + Our Parallel WaveGAN)</li>
</ol>

<p><a href="https://keithito.com/LJ-Speech-Dataset/">LJSpeech dataset</a> is used for the test. Mel-spectrograms (with the range of 70 - 7600 Hz<sup class="footnote-ref" id="fnref:2"><a href="#fn:2">2</a></sup>) were used for local conditioning.</p>

<p><em>Please note that the English samples were not used in the subjective evaluations reported in our paper.</em></p>

<h3 id="analysis-synthesis-1">Analysis/synthesis</h3>

<p><p>That is reflected in definite and comprehensive operating procedures.</p>
<table><thead>
<tr><th>Ground truth</th><th>WaveNet</th><th>ClariNet-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample01]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample01]-2-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample01]-3-ClariNet (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>ClariNet-$L^{(1,2,3)}$</th><th>ClariNet-GAN-$L^{(1,2,3)}$</th><th>Parallel WaveGAN-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample01]-4-ClariNet (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample01]-5-ClariNet-GAN (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample01]-6-Parallel WaveGAN (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>Parallel WaveGAN-$L^{(1,2,3)}$ <font color="#0000cd">(ours)</font></th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample01]-7-Parallel WaveGAN (3spec) (ours).wav" type="audio/wav"></audio></td>
</tr></tbody></table><p>The commission also recommends.</p>
<table><thead>
<tr><th>Ground truth</th><th>WaveNet</th><th>ClariNet-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample02]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample02]-2-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample02]-3-ClariNet (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>ClariNet-$L^{(1,2,3)}$</th><th>ClariNet-GAN-$L^{(1,2,3)}$</th><th>Parallel WaveGAN-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample02]-4-ClariNet (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample02]-5-ClariNet-GAN (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample02]-6-Parallel WaveGAN (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>Parallel WaveGAN-$L^{(1,2,3)}$ <font color="#0000cd">(ours)</font></th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample02]-7-Parallel WaveGAN (3spec) (ours).wav" type="audio/wav"></audio></td>
</tr></tbody></table><p>That the secret service consciously set about the task of inculcating and maintaining the highest standard of excellence and esprit, for all of its personnel.</p>
<table><thead>
<tr><th>Ground truth</th><th>WaveNet</th><th>ClariNet-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample03]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample03]-2-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample03]-3-ClariNet (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>ClariNet-$L^{(1,2,3)}$</th><th>ClariNet-GAN-$L^{(1,2,3)}$</th><th>Parallel WaveGAN-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample03]-4-ClariNet (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample03]-5-ClariNet-GAN (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample03]-6-Parallel WaveGAN (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>Parallel WaveGAN-$L^{(1,2,3)}$ <font color="#0000cd">(ours)</font></th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample03]-7-Parallel WaveGAN (3spec) (ours).wav" type="audio/wav"></audio></td>
</tr></tbody></table><p>This involves tight and unswerving discipline as well as the promotion of an outstanding degree of dedication and loyalty to duty.</p>
<table><thead>
<tr><th>Ground truth</th><th>WaveNet</th><th>ClariNet-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample04]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample04]-2-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample04]-3-ClariNet (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>ClariNet-$L^{(1,2,3)}$</th><th>ClariNet-GAN-$L^{(1,2,3)}$</th><th>Parallel WaveGAN-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample04]-4-ClariNet (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample04]-5-ClariNet-GAN (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample04]-6-Parallel WaveGAN (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>Parallel WaveGAN-$L^{(1,2,3)}$ <font color="#0000cd">(ours)</font></th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample04]-7-Parallel WaveGAN (3spec) (ours).wav" type="audio/wav"></audio></td>
</tr></tbody></table><p>The commission emphasizes that it finds no causal connection between the assassination.</p>
<table><thead>
<tr><th>Ground truth</th><th>WaveNet</th><th>ClariNet-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample05]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample05]-2-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample05]-3-ClariNet (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>ClariNet-$L^{(1,2,3)}$</th><th>ClariNet-GAN-$L^{(1,2,3)}$</th><th>Parallel WaveGAN-$L^{(1)}$</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample05]-4-ClariNet (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample05]-5-ClariNet-GAN (3spec).wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample05]-6-Parallel WaveGAN (1spec).wav" type="audio/wav"></audio></td>
</tr></tbody></table><table><thead>
<tr><th>Parallel WaveGAN-$L^{(1,2,3)}$ <font color="#0000cd">(ours)</font></th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample05]-7-Parallel WaveGAN (3spec) (ours).wav" type="audio/wav"></audio></td>
</tr></tbody></table></p>

<h3 id="text-to-speech-1">Text-to-speech</h3>

<p>We combined our Parallel WaveGAN with <a href="https://arxiv.org/abs/1910.10909">ESPnet-TTS</a>. The systems used here are as follows:</p>

<ul>
<li><strong>Transformer.v3</strong>: Transformer.v3 presented in <a href="https://arxiv.org/abs/1910.10909">ESPnet-TTS</a>.</li>
<li><strong>MoL WaveNet</strong>: WaveNet with mixture of logistics output distribution (shipped with ESPnet). Pre-emphasis/de-emphasis were applied to reduce perceptual noise (similar to <a href="https://arxiv.org/abs/1810.11846">LPCNet</a>).</li>
<li><strong>Parallel WaveGAN</strong>: Our Parallel WaveGAN with multi-resolution spectrogram loss.</li>
</ul>

<p>Note that <strong>Transformer.v3 + MoL WaveNet</strong> is the same as used in <a href="https://espnet.github.io/icassp2020-tts/">https://espnet.github.io/icassp2020-tts/</a>.
Mel-spectrograms (with the range of 70 - 11025 Hz) were used for local conditioning.</p>

<p><p>That is reflected in definite and comprehensive operating procedures.</p>
<table><thead>
<tr><th>Ground truth</th><th>Transformer.v3 + MoL WaveNet</th><th>Transformer.v3 + Parallel WaveGAN</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample01]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/TTS/[LJ-Sample01]-1-MoL-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/TTS/[LJ-Sample01]-2-Parallel WaveGAN.wav" type="audio/wav"></audio></td>
</tr></tbody></table><p>The commission also recommends.</p>
<table><thead>
<tr><th>Ground truth</th><th>Transformer.v3 + MoL WaveNet</th><th>Transformer.v3 + Parallel WaveGAN</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample02]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/TTS/[LJ-Sample02]-1-MoL-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/TTS/[LJ-Sample02]-2-Parallel WaveGAN.wav" type="audio/wav"></audio></td>
</tr></tbody></table><p>That the secret service consciously set about the task of inculcating and maintaining the highest standard of excellence and esprit, for all of its personnel.</p>
<table><thead>
<tr><th>Ground truth</th><th>Transformer.v3 + MoL WaveNet</th><th>Transformer.v3 + Parallel WaveGAN</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample03]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/TTS/[LJ-Sample03]-1-MoL-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/TTS/[LJ-Sample03]-2-Parallel WaveGAN.wav" type="audio/wav"></audio></td>
</tr></tbody></table><p>This involves tight and unswerving discipline as well as the promotion of an outstanding degree of dedication and loyalty to duty.</p>
<table><thead>
<tr><th>Ground truth</th><th>Transformer.v3 + MoL WaveNet</th><th>Transformer.v3 + Parallel WaveGAN</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample04]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/TTS/[LJ-Sample04]-1-MoL-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/TTS/[LJ-Sample04]-2-Parallel WaveGAN.wav" type="audio/wav"></audio></td>
</tr></tbody></table><p>The commission emphasizes that it finds no causal connection between the assassination.</p>
<table><thead>
<tr><th>Ground truth</th><th>Transformer.v3 + MoL WaveNet</th><th>Transformer.v3 + Parallel WaveGAN</th></tr>
</thead><tbody><tr><td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample05]-1-Ground truth.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/TTS/[LJ-Sample05]-1-MoL-WaveNet.wav" type="audio/wav"></audio></td>
<td><audio controls=""><source src="https://r9y9.github.io/demos/audio/icassp2020/LJSpeech/TTS/[LJ-Sample05]-2-Parallel WaveGAN.wav" type="audio/wav"></audio></td>
</tr></tbody></table></p>

<h2 id="references">References</h2>

<ul>
<li>W. Ping, K. Peng, and J. Chen, “ClariNet: Parallel wave generation in end-to-end text-to-speech,” in Proc. ICLR, 2019 (<a href="https://arxiv.org/abs/1807.07281">arXiv</a>).</li>
<li>R. Yamamoto, E. Song, and J.-M. Kim, “Probability density distillation with generative adversarial networks for high-quality parallel waveform generation,” in Proc. INTERSPEECH, 2019, pp. 699–703. (<a href="https://www.isca-speech.org/archive/Interspeech_2019/abstracts/1965.html">ISCA archive</a>)</li>
</ul>

<h2 id="acknowledgements">Acknowledgements</h2>

<p>Work performed with nVoice, Clova Voice, Naver Corp.</p>

<h2 id="citation">Citation</h2>
<pre><code>@inproceedings{yamamoto2020parallel,
  title={Parallel {WaveGAN}: {A} fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram},
  author={Yamamoto, Ryuichi and Song, Eunwoo and Kim, Jae-Min},
  booktitle	= &#34;Proc. of ICASSP&#34;,
  pages={6199--6203},
  year={2020}
}</code></pre><div class="footnotes">

<hr />

<ol>
<li id="fn:1">Note that our work is not closely related to an unsupervised waveform synthesis model, <a href="https://arxiv.org/abs/1802.04208">WaveGAN</a>.
 <a class="footnote-return" href="#fnref:1"><sup>[return]</sup></a></li>
<li id="fn:2">Audio quaility can be improved by using the full-band frequency range, but it may suffer from the over-smoothing problem in TTS.
 <a class="footnote-return" href="#fnref:2"><sup>[return]</sup></a></li>
</ol>
</div>

				
<div class="social">
    <div>
        <a href="https://twitter.com/share" class="twitter-share-button" data-via="r9y9" data-text="Parallel WaveGAN: A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram" data-related="r9y9">Tweet</a>
        <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
    </div>
</div>


			</section>
		</article>
	</main>


	<footer role="contentinfo">
		<div class="hr"></div>
		<address>

		<div class="copyright">Copyright &copy;
			<a href="https://r9y9.github.io/demos/about">Ryuichi YAMAMOTO</a> All rights reserved.

      <a href="https://github.com/r9y9">
				<span class="github">https://github.com/r9y9</span>.
			</a>
		</div>
		</address>
	</footer>

</div>

<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-44433856-1', 'auto');
	ga('send', 'pageview');
</script>

<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
     MathJax.Hub.Config({
         HTML: ["input/TeX","output/HTML-CSS"],
         TeX: {
                Macros: {
                         bm: ["\\boldsymbol{#1}", 1],
                         argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                         argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
                extensions: ["AMSmath.js","AMSsymbols.js"],
                equationNumbers: { autoNumber: "AMS" } },
         extensions: ["tex2jax.js"],
         jax: ["input/TeX","output/HTML-CSS"],
         tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true },
         "HTML-CSS": { availableFonts: ["TeX"],
                       linebreaks: { automatic: true } }
     });
 </script>

 <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       tex2jax: {
         skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
       }
     });
 </script>

 <script type="text/javascript" async
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?...">
 </script>




</body>
</html>

