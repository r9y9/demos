<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>List of demos</title>
    <link>https://r9y9.github.io/demos/</link>
    <description>Recent content on List of demos</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 Oct 2020 23:38:48 +0900</lastBuildDate><atom:link href="https://r9y9.github.io/demos/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Parallel waveform synthesis based on generative adversarial networks with voicing-aware conditional discriminators</title>
      <link>https://r9y9.github.io/demos/projects/icassp2021/</link>
      <pubDate>Wed, 21 Oct 2020 23:38:48 +0900</pubDate>
      
      <guid>https://r9y9.github.io/demos/projects/icassp2021/</guid>
      <description>Preprint: arXiv:2010.14151 (submitted to ICASSP 2021)
Table of contents  Analysis/synthesis samples (Japanese) Text-to-speech samples (Japanese) Bonus: analysis/synthesis samples for CMU ARCTIC (English)  Authors  Ryuichi Yamamoto (LINE Corp.) Eunwoo Song (NAVER Corp.) Min-Jae Hwang (Search Solutions Inc.) Jae-Min Kim (NAVER Corp.)  Abstract This paper proposes voicing-aware conditional discriminators for Parallel WaveGAN-based waveform synthesis systems. In this framework, we adopt a projection-based conditioning method that can significantly improve the discriminatorâ€™s performance.</description>
    </item>
    
    <item>
      <title>Parallel WaveGAN: A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram</title>
      <link>https://r9y9.github.io/demos/projects/icassp2020/</link>
      <pubDate>Mon, 21 Oct 2019 20:18:27 +0900</pubDate>
      
      <guid>https://r9y9.github.io/demos/projects/icassp2020/</guid>
      <description>Preprint: arXiv:1910.11480 (accepted to ICASSP 2020)
 Audio samples (Japanese) Audio samples (English)  Japanese samples were used in the subjective evaluations reported in our paper.
Authors  Ryuichi Yamamoto (LINE Corp.) Eunwoo Song (NAVER Corp.) Jae-Min Kim (NAVER Corp.)  Abstract We propose Parallel WaveGAN1, a distillation-free, fast, and small-footprint waveform generation method using a generative adversarial network. In the proposed method, a non-autoregressive WaveNet is trained by jointly optimizing multi-resolution spectrogram and adversarial loss functions, which can effectively capture the time-frequency distribution of the realistic speech waveform.</description>
    </item>
    
    <item>
      <title>Probability Density Distillation with Generative Adversarial Networks for High-Quality Parallel Waveform Generation</title>
      <link>https://r9y9.github.io/demos/projects/interspeech2019/</link>
      <pubDate>Tue, 25 Jun 2019 17:20:29 +0900</pubDate>
      
      <guid>https://r9y9.github.io/demos/projects/interspeech2019/</guid>
      <description>Preprint: arXiv:1904.04472, Published version: ISCA Archive Interspeech 2019
Authors  Ryuichi Yamamoto (LINE Corp.) Eunwoo Song (NAVER Corp.) Jae-Min Kim (NAVER Corp.)  Abstract This paper proposes an effective probability density distillation (PDD) algorithm for WaveNet-based parallel waveform generation (PWG) systems. Recently proposed teacher-student frameworks in the PWG system have successfully achieved a real-time generation of speech signals. However, the difficulties optimizing the PDD criteria without auxiliary losses result in quality degradation of synthesized speech.</description>
    </item>
    
  </channel>
</rss>
